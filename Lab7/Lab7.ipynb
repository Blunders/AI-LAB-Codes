{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92d0b5e-3fb5-47cb-b05b-eb6702cd72b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd437594-5854-4a77-94fa-837185c6b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the car dataset\n",
    "data = np.genfromtxt('car.data', delimiter=',', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb20c29a-28cf-4661-9304-dc71f348ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for i in range(X.shape[1]):\n",
    "    label_encoders[i] = LabelEncoder()\n",
    "    X[:, i] = label_encoders[i].fit_transform(X[:, i])\n",
    "\n",
    "# Define class labels and attribute values\n",
    "class_labels = ['unacc', 'acc', 'good', 'vgood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeda07e0-05d7-4337-8dcc-ce4c32b14e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split data into training and testing sets\n",
    "def split_data(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "076a50cc-94df-458a-9b07-4e87561f1c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to construct decision tree and evaluate performance\n",
    "def evaluate_tree(X_train, X_test, y_train, y_test, criterian):\n",
    "    # Construct decision tree\n",
    "    tree = DecisionTreeClassifier(criterion=criterian)\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict labels for test set\n",
    "    y_pred = tree.predict(X_test)\n",
    "    \n",
    "    # Calculate confusion matrix and F-score\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=class_labels)\n",
    "    f_score = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
    "    \n",
    "    return accuracy, cm, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8eb3839-79c1-4024-a3fa-eda72f0a96ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9797687861271677\n",
      "Confusion Matrix:\n",
      " [[481   3   0   0]\n",
      " [  1 147   5   1]\n",
      " [  0   4  24   0]\n",
      " [  0   0   0  26]]\n",
      "F1 score: 0.9798905210172479\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "test_size = 0.4\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, test_size)\n",
    "# Perform experiment with entropy\n",
    "accuacy, cm, f_score = evaluate_tree(X_train, X_test, y_train, y_test, 'entropy')\n",
    "print(\"Accuracy:\", accuacy)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"F1 score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f97c8276-6135-4386-b7ba-29224353ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to repeat experiment multiple times\n",
    "def repeat_experiment(X, y, test_size, num_repeats, criterian):\n",
    "    accuracies = []\n",
    "    for _ in range(num_repeats):\n",
    "        X_train, X_test, y_train, y_test = split_data(X, y, test_size)\n",
    "        accuracy, _, _ = evaluate_tree(X_train, X_test, y_train, y_test, criterian)\n",
    "        accuracies.append(accuracy)\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    return avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2022835d-1e7e-4d0f-9d9c-b206077c26c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with entropy: 0.9704479768786125\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "test_size = 0.4\n",
    "num_repeats = 20\n",
    "\n",
    "# Perform experiment with entropy\n",
    "avg_accuracy = repeat_experiment(X, y, test_size, num_repeats, 'entropy')\n",
    "print(\"Average accuracy with entropy:\", avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019c6f36-0989-4798-9f8c-81caa45ee9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with gini: 0.9638728323699421\n",
      "Confusion Matrix with gini:\n",
      " [[474   8   2   0]\n",
      " [  6 142   5   1]\n",
      " [  0   3  25   0]\n",
      " [  0   0   0  26]]\n",
      "F1 score with gini: 0.9642660592362181\n"
     ]
    }
   ],
   "source": [
    "# Perform experiment with gini\n",
    "accuacy, cm, f_score = evaluate_tree(X_train, X_test, y_train, y_test, 'gini')\n",
    "print(\"Accuracy with gini:\", accuacy)\n",
    "print(\"Confusion Matrix with gini:\\n\", cm)\n",
    "print(\"F1 score with gini:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39463258-c1f1-404b-9260-2f865af51f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with Gini index: 0.9696531791907512\n"
     ]
    }
   ],
   "source": [
    "avg_accuracy_gini = repeat_experiment(X, y, test_size, num_repeats, 'gini')\n",
    "print(\"Average accuracy with Gini index:\", avg_accuracy_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1322ee62-34f6-4752-8735-f7dbb338e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9710982658959537\n",
      "Confusion Matrix:\n",
      " [[479   5   0   0]\n",
      " [  3 144   6   1]\n",
      " [  0   5  23   0]\n",
      " [  0   0   0  26]]\n",
      "F1 score: 0.9712393693884904\n",
      "Average accuracy with entropy: 0.9766859344894028\n",
      "Accuracy with gini: 0.9638728323699421\n",
      "Confusion Matrix with gini:\n",
      " [[474   8   2   0]\n",
      " [  6 142   5   1]\n",
      " [  0   3  25   0]\n",
      " [  0   0   0  26]]\n",
      "F1 score with gini: 0.9642660592362181\n",
      "Average accuracy with Gini index: 0.9712909441233141\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "test_size = 0.3\n",
    "num_repeats = 20\n",
    "\n",
    "# Perform experiment with entropy\n",
    "accuacy, cm, f_score = evaluate_tree(X_train, X_test, y_train, y_test, 'entropy')\n",
    "print(\"Accuracy:\", accuacy)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"F1 score:\", f_score)\n",
    "avg_accuracy = repeat_experiment(X, y, test_size, num_repeats, 'entropy')\n",
    "print(\"Average accuracy with entropy:\", avg_accuracy)\n",
    "\n",
    "# Perform experiment with gini\n",
    "accuacy, cm, f_score = evaluate_tree(X_train, X_test, y_train, y_test, 'gini')\n",
    "print(\"Accuracy with gini:\", accuacy)\n",
    "print(\"Confusion Matrix with gini:\\n\", cm)\n",
    "print(\"F1 score with gini:\", f_score)\n",
    "avg_accuracy_gini = repeat_experiment(X, y, test_size, num_repeats, 'gini')\n",
    "print(\"Average accuracy with Gini index:\", avg_accuracy_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "692f6342-fb61-4dc3-b098-512365941b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9739884393063584\n",
      "Confusion Matrix:\n",
      " [[479   5   0   0]\n",
      " [  3 145   5   1]\n",
      " [  0   4  24   0]\n",
      " [  0   0   0  26]]\n",
      "F1 score: 0.9741041904005581\n",
      "Average accuracy with entropy: 0.9812138728323699\n",
      "Accuracy with gini: 0.9696531791907514\n",
      "Confusion Matrix with gini:\n",
      " [[476   6   2   0]\n",
      " [  4 144   5   1]\n",
      " [  0   3  25   0]\n",
      " [  0   0   0  26]]\n",
      "F1 score with gini: 0.9700678127234541\n",
      "Average accuracy with Gini index: 0.9777456647398843\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "test_size = 0.2\n",
    "num_repeats = 20\n",
    "\n",
    "# Perform experiment with entropy\n",
    "accuacy, cm, f_score = evaluate_tree(X_train, X_test, y_train, y_test, 'entropy')\n",
    "print(\"Accuracy:\", accuacy)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"F1 score:\", f_score)\n",
    "avg_accuracy = repeat_experiment(X, y, test_size, num_repeats, 'entropy')\n",
    "print(\"Average accuracy with entropy:\", avg_accuracy)\n",
    "\n",
    "# Perform experiment with gini\n",
    "accuacy, cm, f_score = evaluate_tree(X_train, X_test, y_train, y_test, 'gini')\n",
    "print(\"Accuracy with gini:\", accuacy)\n",
    "print(\"Confusion Matrix with gini:\\n\", cm)\n",
    "print(\"F1 score with gini:\", f_score)\n",
    "avg_accuracy_gini = repeat_experiment(X, y, test_size, num_repeats, 'gini')\n",
    "print(\"Average accuracy with Gini index:\", avg_accuracy_gini)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
